{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso práctico: Extractor de comandas\n",
    "\n",
    "Una importante cadena de restaurantes quiere implantar un sistema de comandas por chat, de esta forma los clientes simplemente tendrán que escribir su comanda por una tablet en la mesa y el asistente virtual se encargará de gestionar el pedido con la cocina y los camareros.\n",
    "\n",
    "El restaurante necesita tener un listado de los platos y las bebidas por separado junto con el número de unidades que se piden de cada elemento.\n",
    "\n",
    "## Importación de librerias\n",
    "\n",
    "Trabajaremos con la librería NLTK, con el tokenizador incluido en la librería, el corpus cess_esp y los 4 taggers vistos en la unidad. Tendremos que importar también el RegEx Parser de NLTK.\n",
    "\n",
    "Por último, como complementos no obligatorio pero que utilizaremos para dar formato o hacer más sencillo el trabajo, train_test_split de sklearn y pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la librería base NLTK\n",
    "import nltk\n",
    "\n",
    "#Importamos el componente de NLTK para tokenizar\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Importamos el corpus CESS en Español\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "#Taggers ngrams y HMM\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "#RegEx Parser\n",
    "from nltk.chunk.regexp import *\n",
    "\n",
    "\n",
    "#Esto nos permitirá crear los conjuntos de test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importamos por último pands\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya tenemos todo lo necesario para emprezar a trabajar con los corpus y los taggers.\n",
    "\n",
    "## Entrenamiento de los taggers\n",
    "\n",
    "Para entrenar los taggers lo que tenemos que hacer es traernos el corpus taggeado en español. Antes, veamos que contiene ese corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_Águila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japonés', 'Mitsubishi_Corporation', 'para', 'poner_en_marcha', 'una', 'central', 'de', 'gas', 'de', '495', 'megavatios', '.'], ['Una', 'portavoz', 'de', 'EDF', 'explicó', 'a', 'EFE', 'que', 'el', 'proyecto', 'para', 'la', 'construcción', 'de', 'Altamira_2', ',', 'al', 'norte', 'de', 'Tampico', ',', 'prevé', 'la', 'utilización', 'de', 'gas', 'natural', 'como', 'combustible', 'principal', 'en', 'una', 'central', 'de', 'ciclo', 'combinado', 'que', 'debe', 'empezar', 'a', 'funcionar', 'en', 'mayo_del_2002', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cess_esp.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cess_esp.tagged_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos con el comando `cess_esp.sents()` nos traemos un conjunto de frases tokenizadas de distintas temáticas.\n",
    "\n",
    "Y con el comando `cess_esp.tagged_sents()` nos traemos ese mismo conjunto de frases ya taggeadas.\n",
    "\n",
    "Ahora lo que haremos será crear 2 conjuntos de tokens taggeados. Uno que contenga el 90% de los tokens y otro que contenga el 10%, uno para train y otro para test respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token de entrenamiento: 5427 \n",
      "Tokens de test:     603\n"
     ]
    }
   ],
   "source": [
    "#Generamos los conjuntos de Train y Test\n",
    "data_train, data_test = train_test_split(cess_esp.tagged_sents(), test_size=0.10, random_state=1)\n",
    "\n",
    "print('Token de entrenamiento:',len(data_train),\n",
    "      '\\nTokens de test:    ',len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo los conjuntos ya creados, pasamos a entrenar los taggers. \n",
    "\n",
    "Para entrenar los **ngram** deberemos ejecutar el tagger con el corpus, por ejemplo `UnigramTagger(data_train)`. Veremos que los ngram pueden tener como backoff otro ngram.\n",
    "\n",
    "En el caso de **HiddenMarkovModelTagger** deberemos ejecutar la función `.train()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram  = UnigramTagger(data_train)\n",
    "bigram   = BigramTagger(data_train, backoff=unigram)\n",
    "trigram  = TrigramTagger(data_train, backoff=bigram)\n",
    "hmm      = HiddenMarkovModelTagger.train(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenados los taggers, vamos a evaluar cómo es el tendimiento de cada uno de ellos con el conjunto de test. Para evaluarlo tenemos que utilizar la función `train()`, para todos los taggers. Veamos qué tal funciona cada uno de ellos.\n",
    "\n",
    "Cuando ejecutes el entrenamiento presta atención al tiempo que tarda cada uno de los taggers en mostrar la puntuación. Mientras que los ngram son bastante rápidos para extraer la información, el HMM tarda más tiempo en obtener los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 87.27 %\n",
      "Acierto con bigramas:  88.78 %\n",
      "Acierto con trigramas: 88.77 %\n",
      "Acierto con HMMs:      89.57 %\n"
     ]
    }
   ],
   "source": [
    "print ('Acierto con unigramas: %.2f %%' % (unigram.evaluate(data_test)*100))\n",
    "print ('Acierto con bigramas:  %.2f %%' % (bigram.evaluate(data_test)*100))\n",
    "print ('Acierto con trigramas: %.2f %%' % (trigram.evaluate(data_test)*100))\n",
    "print ('Acierto con HMMs:      %.2f %%' % (hmm.evaluate(data_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos volver a entrenar los taggers con los datos de test. Aunque no apreciaremos una gran mejora en terminos generales, como el volumen de datos que estamos utilizando es pequeño, nos será de ayuda.\n",
    "\n",
    "Veremos, que si evaluamos los taggers de nuevo en el conjunto de test, obtendremos casi un 100% de acierto. Esta mejoría es mayor en los ngramas puesto que son reglas más 'logicas' por así decirlo, por lo que con pequeñs vólumenes de datos veremos mayor acierto. En cambio, en el HMM, vemos mejor mejoría en el caso de evaluar sobre los datos pero en aquellos tokens no entrenados tendremos mejor rendimiento que el resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 96.67 %\n",
      "Acierto con bigramas:  98.86 %\n",
      "Acierto con trigramas: 99.56 %\n",
      "Acierto con HMMs:      93.62 %\n"
     ]
    }
   ],
   "source": [
    "unigram  = UnigramTagger(data_test)\n",
    "bigram   = BigramTagger(data_test, backoff=unigram)\n",
    "trigram  = TrigramTagger(data_test, backoff=bigram)\n",
    "hmm      = HiddenMarkovModelTagger.train(data_test)\n",
    "\n",
    "print ('Acierto con unigramas: %.2f %%' % (unigram.evaluate(data_test)*100))\n",
    "print ('Acierto con bigramas:  %.2f %%' % (bigram.evaluate(data_test)*100))\n",
    "print ('Acierto con trigramas: %.2f %%' % (trigram.evaluate(data_test)*100))\n",
    "print ('Acierto con HMMs:      %.2f %%' % (hmm.evaluate(data_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto que el HMM tiene mejor rendimiento, a priori, utilizaremos este para elaborar nuestro bot de comandas.\n",
    "\n",
    "## Comenzar a elaborar el bot\n",
    "\n",
    "Ahora crearemos una frase de la temática de nuestro bot para ver cómo es el rendimiento con nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_text = 'Quiero unos macarrones con queso y una cerveza'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso será elaborar los tokens de la frase. Para los taggers no es necesario que eliminemos las stopwords, lematicemos o derivemos, al contrario. Si hacemos todos estos pasos estaremos eliminando información que utilizarán los taggers para encontrar las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quiero', 'unos', 'macarrones', 'con', 'queso', 'y', 'una', 'cerveza']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(food_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tengamos los tokens, utilzaremos la función `.tag()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Quiero', 'da0mp0'),\n",
       " ('unos', 'di0mp0'),\n",
       " ('macarrones', 'ncmp000'),\n",
       " ('con', 'sps00'),\n",
       " ('queso', 'np0000l'),\n",
       " ('y', 'cc'),\n",
       " ('una', 'di0fs0'),\n",
       " ('cerveza', 'ncfs000')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_tagged = hmm.tag(tokens)\n",
    "food_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los tags obtenidos no son del todo correctos. Para comprobarlos, debemos revisar los tags EAGLES del enlace facilitado en el temario: https://www.cs.upc.edu/~nlp/tools/parole-sp.html\n",
    "\n",
    "De forma resumida, utilizaremos estos tags, aunque podemos tener variaciones e incorporar otros;\n",
    "\n",
    "- **ncms000** : nombre común masculino singular\n",
    "- **ncfs000** : nombre común femenino singular\n",
    "- **ncmp000** : nombre común masculino plural\n",
    "- **ncfp000** : nombre común femenino plural\n",
    "\n",
    "- **np0000p/np00001** : nombre propio (La incluimos porque fijandonos en como etiqueta nuestros ejemplos podemos comprobar que para algunas palabras le pone este etiquetado(ej: bocadillo de atún). Tambien podría darse el caso de que alguna comida siguiera esta estructura correctamente (ej: pizza de Toni)\n",
    "\n",
    "\n",
    "- **di0ms0** : determinante indefinido masculino singular\n",
    "- **di0fs0** : determinante indefinido femenino singular\n",
    "- **di0mp0** : determinante indefinido masculino plural\n",
    "- **di0fp0** : determinante indefinido femenino plural\n",
    "- **dn0cp0** : determinante indefinido comun plural\n",
    "\n",
    "\n",
    "- **sps00** : Preposición\n",
    "\n",
    "\n",
    "- **da0ms0**: el\n",
    "- **da0fs0**: la\n",
    "- **da0mp0**: los\n",
    "- **da0fp0**: las\n",
    "- **da0ns0**: lo\n",
    "\n",
    "Repasemos la frase:\n",
    "\n",
    " * ('Quiero', 'da0mp0') -> Taggeado como un determinante, debería ser: vmpip1s0 que corresponde a presente de indicativo\n",
    " * ('unos', 'di0mp0') -> Taggeado como determinante masculino, debería ser: mcmp00 que corresponde a un numeral ordinal masculino\n",
    " * ('macarrones', 'ncmp000'), -> **Correcto**: Taggeado como Sustantivo Común Masculino Plural\n",
    " * ('con', 'sps00'), -> **Correcto**: Taggeado como preposición\n",
    " * ('queso', 'np0000l'), -> Taggeado como Sustantivo Propio, debería ser: ncms000 sustantivo común masculino singular\n",
    " * ('y', 'cc'),-> **Correcto**: Taggeado como conjunción coordinada\n",
    " * ('una', 'di0fs0'),-> Taggeado como determinante femenino, debería ser: mcfp00 que corresponde a un numeral ordinal femenino\n",
    " * ('cerveza', 'ncfs000')-> -> **Correcto**: Taggeado como sustantivo femenino singular\n",
    " \n",
    " Como hemos visto, correctamente taggeados tendríamos 4 tokens de 8, un 50% de aciertos. Si evaluamos estos tags con el rendimiento de, por ejemplo el trigram ¿Qué % de acierto tendremos? Comprobemoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 50.00 %\n",
      "Acierto con bigramas:  50.00 %\n",
      "Acierto con trigramas: 50.00 %\n",
      "Acierto con HMMs:      100.00 %\n"
     ]
    }
   ],
   "source": [
    "print ('Acierto con unigramas: %.2f %%' % (unigram.evaluate([food_tagged])*100))\n",
    "print ('Acierto con bigramas:  %.2f %%' % (bigram.evaluate([food_tagged])*100))\n",
    "print ('Acierto con trigramas: %.2f %%' % (trigram.evaluate([food_tagged])*100))\n",
    "print ('Acierto con HMMs:      %.2f %%' % (hmm.evaluate([food_tagged])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, HMM dice que su acierto es del 100%, tiene lógica puesto que es ese tagger el que ha hecho los tags. En cambio el resto de los tags, coinciden en la corrección que hemos hecho, aunque esto no quiere decir que esos tags acierten 8 de 8 etiquetas, comprobemoslo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigramas: [('Quiero', None), ('unos', 'di0mp0'), ('macarrones', None), ('con', 'sps00'), ('queso', None), ('y', 'cc'), ('una', 'di0fs0'), ('cerveza', None)]\n",
      "Bigramas:  [('Quiero', None), ('unos', 'di0mp0'), ('macarrones', None), ('con', 'sps00'), ('queso', None), ('y', 'cc'), ('una', 'di0fs0'), ('cerveza', None)]\n",
      "Trigramas:  [('Quiero', None), ('unos', 'di0mp0'), ('macarrones', None), ('con', 'sps00'), ('queso', None), ('y', 'cc'), ('una', 'di0fs0'), ('cerveza', None)]\n"
     ]
    }
   ],
   "source": [
    "print ('Unigramas:', (unigram.tag(tokens)))\n",
    "print ('Bigramas: ', (bigram.tag(tokens)))\n",
    "print ('Trigramas: ', (trigram.tag(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos visto estos resultados, confirmamos que el que mejor rendimiento ha tenido es HMM, que ha encontrado etiquetas, que aunque no del todo correctas han sido aproximadas, en algunos casos ha confundido el género, en otros el número aunque esto no afectaría demasiado a nuestra extracción de información. Pero en general ha etiquetado en tipo de palabra 6 de los 8 tokens.\n",
    "\n",
    "Los ngrams, no han podido identificar los tokens en el 50% de los casos. Por lo que habríamos tenido problemas a la hora de utilizarlos como taggers.\n",
    "\n",
    "## Corregir el tagger\n",
    "\n",
    "Ahora que hemos corregido los tags, es hora de volver a entrenar el tagger con la frase correcta, por lo que vamos a ello.\n",
    "Vamos a también a trabajar con el foodTagger (es un HMM entrenado con nuestras frases de comida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_tokens = [('Quiero', 'vmpip1s0'), ('unos', 'mcmp00'), ('macarrones', 'ncmp000'), ('con', 'sps00'), ('queso', 'ncms000'), ('y', 'cc'), ('una', 'mcfp00'), ('cerveza', 'ncfs000')]\n",
    "\n",
    "foodTagger = hmm.train([corrected_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, una vez entrenado el tagger, si volvemos a pasar la misma frase acertará con todos ellos puesto que está entrenado para detectar los tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Quiero', 'vmpip1s0'),\n",
       " ('unos', 'mcmp00'),\n",
       " ('macarrones', 'ncmp000'),\n",
       " ('con', 'sps00'),\n",
       " ('queso', 'ncms000'),\n",
       " ('y', 'cc'),\n",
       " ('una', 'mcfp00'),\n",
       " ('cerveza', 'ncfs000')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_tagged = foodTagger.tag(tokens)\n",
    "food_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La corrección del tagger es un proceso que deberemos elaborar repetidamente para conseguir mejorar los resultados. Es un proceso que podríamos acortar en gran manera si tuviesemos un corpus con miles de frases y tokens como el inicial, pero de nuestro contexto en concreto.\n",
    "\n",
    "## Elaborar una función que reconozca las comandas\n",
    "\n",
    "Para ello tendremos que utilizar RegEx Parser y las reglas lógicas. En nuestro caso, podemos utilizar las que hemos visto en la teoría de esta unidad.\n",
    "\n",
    "- nombre común : *macarrones*\n",
    "\n",
    "- nombre común + nombre (común/propio) : *pizza margarita*\n",
    "\n",
    "- nombre común + preposición + nombre(común/propio) : *bocadillo de atún*\n",
    "\n",
    "- nombre común + preposición + artículo + nombre(común/propio) : *lentejas a la riojana*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas = r'''\n",
    "    cantidad: {<mccp00>}\n",
    "    comida: {<ncms000|ncfs000|ncmp000|ncfp000>*<sps00>*<da0ms0|da0fs0|da0mp0|da0fp0|da0ns0>*<ncms000|ncfs000|ncmp000|ncfp000|np0000l|np0000p>}\n",
    "    cantidad: {<di0ms0|di0fs0|di0mp0|di0fp0|dn0cp0|mcmp00|mcfp00> || <mcmp00>* || <mcfp00> }\n",
    "      '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya tenemos la gramática creada, vamos a crear la función del regex que extraiga la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegexP = nltk.RegexpParser(reglas)\n",
    "\n",
    "def parsear(phrase):\n",
    "    return RegexP.parse(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Quiero/vmpip1s0\n",
      "  (cantidad unos/mcmp00)\n",
      "  (comida macarrones/ncmp000 con/sps00 queso/ncms000)\n",
      "  y/cc\n",
      "  (cantidad una/mcfp00)\n",
      "  (comida cerveza/ncfs000))\n"
     ]
    }
   ],
   "source": [
    "frase_regex = parsear(corrected_tokens)\n",
    "print(frase_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para extraer los nodos clasificados\n",
    "\n",
    "Una vez hemos conseguido identificar la comida y la cantidad de la comanda, generaremos un JSON con los datos de la comanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genera_comanda(tree):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    item = {}\n",
    "    item['item'] = None\n",
    "    item['cantidad'] = 0\n",
    "    \n",
    "    elementos = 0\n",
    "    \n",
    "    #En primer lugar contaremos cuantos elementos hay en el pedido\n",
    "    for nodo in tree:\n",
    "        if type(nodo) == tuple:\n",
    "            continue\n",
    "        tipo = nodo.label()\n",
    "        if tipo == 'comida':\n",
    "            elementos += 1\n",
    "            \n",
    "    #Ahora generaremos cada línea de pedido con sus cantidades\n",
    "    for nodo in tree:\n",
    "        if type(nodo) == tuple:\n",
    "            continue\n",
    "        \n",
    "        count = 0\n",
    "        valor = ''\n",
    "        \n",
    "        for elemento in nodo:\n",
    "            count += 1\n",
    "            palabra, categoria = elemento\n",
    "                \n",
    "            if count == 1:\n",
    "                valor = valor + palabra\n",
    "            else:\n",
    "                valor = valor + ' ' + palabra\n",
    "            \n",
    "            if nodo.label() == 'cantidad':\n",
    "                item['cantidad'] = valor\n",
    "            else:\n",
    "                item['item'] = valor\n",
    "        \n",
    "        if nodo.label() == 'comida':\n",
    "            result.append(item)\n",
    "            item = {}\n",
    "            #print(item)\n",
    "        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item': 'macarrones con queso', 'cantidad': 'unos'},\n",
       " {'cantidad': 'una', 'item': 'cerveza'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genera_comanda(frase_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que la función nos genera la comada, generaremos una nueva función que lo haga desde 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesa_frase(frase):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(frase)\n",
    "    print('Tokens:')\n",
    "    print(tokens)\n",
    "    print('\\n', '-----------------------------------------', '\\n')\n",
    "    tags = foodTagger.tag(tokens)\n",
    "    print('TAGS:')\n",
    "    print(tags)\n",
    "    print('\\n', '-----------------------------------------', '\\n')\n",
    "    parsed = parsear(tags)\n",
    "    print('Parsed:')\n",
    "    print(parsed)\n",
    "    print('\\n', '-----------------------------------------', '\\n')\n",
    "    \n",
    "    return genera_comanda(parsed)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último, testeamos la función que hemos creado para analizar frases completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['pedir', 'dos', 'pizzas', 'cuatro', 'quesos', 'y', 'cinco', 'fantas']\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "TAGS:\n",
      "[('pedir', 'vmpip1s0'), ('dos', 'mcmp00'), ('pizzas', 'ncmp000'), ('cuatro', 'sps00'), ('quesos', 'ncms000'), ('y', 'cc'), ('cinco', 'mcfp00'), ('fantas', 'ncfs000')]\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "Parsed:\n",
      "(S\n",
      "  pedir/vmpip1s0\n",
      "  (cantidad dos/mcmp00)\n",
      "  (comida pizzas/ncmp000 cuatro/sps00 quesos/ncms000)\n",
      "  y/cc\n",
      "  (cantidad cinco/mcfp00)\n",
      "  (comida fantas/ncfs000))\n",
      "\n",
      " ----------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'item': 'pizzas cuatro quesos', 'cantidad': 'dos'},\n",
       " {'cantidad': 'cinco', 'item': 'fantas'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraseTest = 'pedir dos pizzas cuatro quesos y cinco fantas'\n",
    "\n",
    "procesa_frase(fraseTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque esta frase funciona, es posible que otras no lo hagan, por ejemplo si no ponemos un verbo antes de la comanda, hagamos una prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['dos', 'pizzas', 'cuatro', 'quesos', 'y', 'cinco', 'fantas']\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "TAGS:\n",
      "[('dos', 'vmpip1s0'), ('pizzas', 'mcmp00'), ('cuatro', 'ncmp000'), ('quesos', 'sps00'), ('y', 'ncms000'), ('cinco', 'cc'), ('fantas', 'mcfp00')]\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "Parsed:\n",
      "(S\n",
      "  dos/vmpip1s0\n",
      "  (cantidad pizzas/mcmp00)\n",
      "  (comida cuatro/ncmp000 quesos/sps00 y/ncms000)\n",
      "  cinco/cc\n",
      "  (cantidad fantas/mcfp00))\n",
      "\n",
      " ----------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'item': 'cuatro quesos y', 'cantidad': 'pizzas'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraseTest = 'dos pizzas cuatro quesos y cinco fantas'\n",
    "procesa_frase(fraseTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta frase únicamente ha identificado, y de forma erronea, por lo que vamos a corregirla y a entrenar nuestro tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_order = [('dos', 'mccp00'), ('pizzas', 'ncmp000'), ('cuatro', 'sps00'), ('quesos', 'ncms000'), ('y', 'cc'), ('cinco', 'mcfp00'), ('fantas', 'ncfs000')]\n",
    "\n",
    "foodTagger = foodTagger.train([corrected_order])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos entrenado de nuevo nuestro tagger, por lo que podemos volver a probar la misma frase y comprobar su rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['dos', 'pizzas', 'cuatro', 'quesos', 'y', 'cinco', 'fantas']\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "TAGS:\n",
      "[('dos', 'mccp00'), ('pizzas', 'ncmp000'), ('cuatro', 'sps00'), ('quesos', 'ncms000'), ('y', 'cc'), ('cinco', 'mcfp00'), ('fantas', 'ncfs000')]\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "Parsed:\n",
      "(S\n",
      "  (cantidad dos/mccp00)\n",
      "  (comida pizzas/ncmp000 cuatro/sps00 quesos/ncms000)\n",
      "  y/cc\n",
      "  (cantidad cinco/mcfp00)\n",
      "  (comida fantas/ncfs000))\n",
      "\n",
      " ----------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'item': 'pizzas cuatro quesos', 'cantidad': 'dos'},\n",
       " {'cantidad': 'cinco', 'item': 'fantas'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procesa_frase(fraseTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['dos', 'hamburguesas']\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "TAGS:\n",
      "[('dos', 'mccp00'), ('hamburguesas', 'ncmp000')]\n",
      "\n",
      " ----------------------------------------- \n",
      "\n",
      "Parsed:\n",
      "(S (cantidad dos/mccp00) (comida hamburguesas/ncmp000))\n",
      "\n",
      " ----------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'item': 'hamburguesas', 'cantidad': 'dos'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procesa_frase('dos hamburguesas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con esto ya tendríamos listo nuestro bot procesador de comandas. Por supuesto tiene margen de mejora y necesidad de mayor entrenamiento, pero tiene la funcionalidad requerida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
