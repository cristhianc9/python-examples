{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e76907",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "717cfde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#ejecutar en cmd para inglés python3 -m spacy download en_core_web_sm  \n",
    "#ejecutar en cmd para español python3 -m spacy download es_core_news_sm  \n",
    "\n",
    "#nlp=spacy.load('en_core_web_sm') #inglés\n",
    "nlp = spacy.load('es_core_news_sm') #español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4dbe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Soy un texto. Normalmente soy más largo y más grande. Que no te engañe mi tamaño.\"\n",
    "doc = nlp(text) # Crea un objeto de spacy tipo nlp\n",
    "tokens = [t.orth_ for t in doc] # Crea una lista con las palabras del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a39a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a3a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_tokens = [t.orth_ for t in doc if not t.is_punct | t.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49daa424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texto', 'Normalmente', 'engañe', 'tamaño']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f88869",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [t.lower() for t in lexical_tokens if len(t) > 3 and t.isalpha()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d639b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    doc = nlp(text)\n",
    "    words = [t.orth_ for t in doc if not t.is_punct | t.is_stop]\n",
    "    lexical_tokens = [t.lower() for t in words if len(t) > 3 and     \n",
    "    t.isalpha()]\n",
    "    return lexical_tokens\n",
    "word_list = normalize(\"Soy un texto de prueba. ¿Cuántos tokens me quedarán después de la normalización?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4af6ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texto', 'prueba', 'tokens', 'quedarán', 'normalización']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30c19228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluye los pronombres de nuestra lista de lemas\n",
    "lemmas_no_pron = [tok.lemma_.lower() for tok in doc if tok.pos_ != 'PRON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6f6bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para extraer raíces de las palabras: stemming\n",
    "import nltk\n",
    "from nltk import SnowballStemmer\n",
    "spanishstemmer=SnowballStemmer('spanish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1827ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Soy un texto que pide a gritos que lo procesen.Por eso yo canto, tú cantas, ella canta, nosotros cantamos, cantan…\"\n",
    "tokens = normalize(text) # crear una lista de tokens\n",
    "stems = [spanishstemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "160e118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'pid', 'grit', 'proces', 'cant', 'cant', 'cant', 'cant', 'cant']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91e625d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777997f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
