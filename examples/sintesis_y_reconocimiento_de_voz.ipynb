{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidad 5 - Reconocimiento y síntesis de voz\n",
    "\n",
    "En este notebook veremos como reconocer frases de voz para transcribirlas a texto y viceversa.\n",
    "\n",
    "## Requerimientos\n",
    "\n",
    "Para poder seguir correctamente este notebook necesitaremos tener micrófono en nuestro ordenador y las siguientes librerías instaladas:\n",
    "\n",
    "* SpeechRecognition\n",
    "* Pyaudio\n",
    "\n",
    "En caso de no tenerlas instaladas, aquí tienes cómo instalarlas.\n",
    "\n",
    "### SpeechRecognition\n",
    "\n",
    "1. Abriremos una consola de “Anaconda Promt”\n",
    "2. Ejecutaremos el comando: `pip install SpeechRecognition`\n",
    "\n",
    "### Pyaudio\n",
    "\n",
    "1. Abriremos una consola de “Anaconda Promt”\n",
    "2. Ejecutaremos el comando: `conda install pyaudio`\n",
    "3. A continuación este: `conda install -c anaconda portaudio`\n",
    "4. Por último este:`pip install pyttsx3`\n",
    "\n",
    "## Parte 1: Reconocimiento de voz\n",
    "\n",
    "En primer lugar vamos a ver cómo reconocer la voz y convertirla a texto\n",
    "\n",
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la instalacia de reconocimiento de voz\n",
    "\n",
    "Para crear la instancia basta con ejecutar el comando `Recognizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos la fuente de audio\n",
    "\n",
    "Como comentamos en la unidad podemos utilizar audio en 2 tipos de fuente, bien desde un fichero en formato WAV o desde el micrófono, veamos ambos procesos.\n",
    "\n",
    "#### Audio desde fichero\n",
    "\n",
    "El proceso es muy sencillo, bastaría con cargar el archivo utilizando el comando `AudioFile('RUTA_DEL_ARCHIVO')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sr.AudioFile('./example.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio desde fichero\n",
    "\n",
    "En primer lugar tenemos que cargar el audio del micrófono con el comando `Microphone()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de tener algún error al ejecutar el comando Microphone(), descomentar estas líneas\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando `Microphone()` seleccionará por defecto el micrófono que nuestro sistema tenga predeterminado, pero podemos seleccionar cualquier otro instalado en el sistema, incluso la salida de audio que podríamos utilizar para transcribir, por ejemplo, una reunión.\n",
    "\n",
    "Para ver la lista de micrófonos ejecutaremos el comando `list_microphone_names()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Micrófono (USB Microphone)',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " '6 - U28E590 (AMD High Definitio',\n",
       " '4 - PHL 223V7 (AMD High Definit',\n",
       " 'Audio digital (S/PDIF) (High De',\n",
       " '3 - PHL 223V7 (AMD High Definit',\n",
       " 'Output (AMD HD Audio DP out #5)',\n",
       " 'Output (AMD HD Audio HDMI out #3)',\n",
       " 'Output (AMD HD Audio HDMI out #2)',\n",
       " 'SPDIF Out (HD Audio SPDIF out)',\n",
       " 'Micrófono (USB Microphone)',\n",
       " 'Auriculares con micrófono (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(Sudio Ett))',\n",
       " 'Auriculares con micrófono (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(Sudio Ett))',\n",
       " 'Auriculares ()']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone().list_microphone_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar cualquier otro micrónono de la lista basta con especificar el orden que tiene en la lista dentro del comando Micrphone() -> `Microphone(device_index=12)` Seleccionará el 12º de la lista, en este caso \"Micrófono (USB Microphone)\"\n",
    "\n",
    "#### Crear el fragmento de audio\n",
    "\n",
    "Una vez tenemos el input, bien desde audio o desde el micrófono, lo establecemos como source. En este proceso es cuando eliminaríamos el ruido de fondo con el comando `adjust_for_ambient_noise()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mic_conversion():\n",
    "    with mic as source:\n",
    "        \n",
    "        #Ajustes de sonido ambiente\n",
    "        instance.adjust_for_ambient_noise(source)\n",
    "        \n",
    "        #Comenzar a grabar el audio\n",
    "        audio = instance.listen(source)\n",
    "        \n",
    "        #Transcribir usando la api de google\n",
    "        transcript = instance.recognize_google(audio, language='es-ES', show_all = True)\n",
    "        \n",
    "        #Devolvemos el resultado obtenido\n",
    "        return transcript ['alternative'][0]['transcript']\n",
    "        \n",
    "def audio_conversion():\n",
    "    with file as source:\n",
    "        \n",
    "        instance.adjust_for_ambient_noise(source)\n",
    "        \n",
    "        audio = instance.record(source)\n",
    "        \n",
    "        transcript = instance.recognize_google(audio, language='es-ES', show_all = True)\n",
    "        \n",
    "        return transcript ['alternative'][0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a probar las funciones que hemos creado.\n",
    "\n",
    "#### Función de micrófono\n",
    "\n",
    "Cuando ejecutemos el comando, debemos esperar un segundo para empezar a hablar y evitar que se nos corte el principio del audio. La función dejará de grabar automáticamente tras dejar de hablar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'transcript': 'lista de la compra 4', 'confidence': 0.89029455}, {'transcript': 'lista de la compra cuatro'}, {'transcript': 'listadelacompra 4'}, {'transcript': 'listadelacompra cuatro'}], 'final': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lista de la compra 4'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_conversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de procesamiento de audio\n",
    "\n",
    "Ahora haremos lo mismo con la función del texto. No nos reconocerá el principio del texto, por lo que el reconocimiento no será del todo correcto.\n",
    "\n",
    "El texto contenido en el audio es el siguiente:\n",
    "\n",
    "`La Policía Nacional ha finalizado hoy la implantación de esta nueva versión del DNI y desde hoy únicamente se expedirá este DNI Europeo para todos los ciudadanos españoles.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final ha finalizado y la implantación de esta nueva versión del DNI desde hoy únicamente se expedirá este DNI europeo para todos los ciudadanos españoles'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_conversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Síntesis de voz\n",
    "\n",
    "En primer lugar vamos a ver cómo reconocer la voz y convertirla a texto\n",
    "\n",
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motor de reconocimiento\n",
    "\n",
    "Lo primero que debemos hacer es crear el motor de reconocimiento, para ello basta con ejecutar el comando `init()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración dle motor\n",
    "\n",
    "Una vez creado, toca configurarlo. En nuestro caso, la configuración será estática, puesto que estableceremos el idioma y la velocidad y no necesitaremos modificar habitualmente los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuración de la velocidad\n",
    "engine.setProperty('rate', 140)\n",
    "\n",
    "#Configuración del idioma\n",
    "engine.setProperty('voice', 'spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para hablar\n",
    "\n",
    "Ahora solo nos queda crear una función para que nuestro motor hable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def habla(texto):\n",
    "    engine.say(texto)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar la función\n",
    "\n",
    "Ahora solo queda probar la función que hemos creado y escuchar cómo se procesa el texto. Vamos a utilizar el mismo texto para comparar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'La Policía Nacional ha finalizado hoy la implantación de esta nueva versión del DNI y desde hoy únicamente se expedirá este DNI Europeo para todos los ciudadanos españoles.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "habla(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
